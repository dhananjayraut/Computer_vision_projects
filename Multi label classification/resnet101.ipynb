{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['resnet101', 'imet-2019-fgvc6']\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "import os\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import torch\n",
    "import random\n",
    "import torchvision\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils ,models\n",
    "from PIL import Image, ImageFilter\n",
    "import matplotlib.patches as patches\n",
    "pd.set_option('display.width', 120)\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "# Any results you write to the current directory are saved as output.\n",
    "# All paths are relative to kaggle kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' from here  https://www.kaggle.com/c/imet-2019-fgvc6/discussion/87675#latest-516375'''\n",
    "def seed_everything(seed=1234):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "seed_everything()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '../input/imet-2019-fgvc6/' #root directory\n",
    "SIZE = 400 #image height and width\n",
    "EPOCH = 20 #number of epochs to train\n",
    "BATCH_SIZE = 128 #batch size\n",
    "PRINT_EVERY = int(10000/BATCH_SIZE) #print loss after these many batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(109237, 2)\n",
      "(1103, 2)\n",
      "                 id        attribute_ids\n",
      "0  1000483014d91860          147 616 813\n",
      "1  1000fe2e667721fe       51 616 734 813\n",
      "2  1001614cb89646ee                  776\n",
      "3  10041eb49b297c08  51 671 698 813 1092\n",
      "4  100501c227f8beea  13 404 492 903 1093\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv(root + 'train.csv')\n",
    "train_path = root + 'train/'\n",
    "df_label = pd.read_csv(root + 'labels.csv')\n",
    "print(df_train.shape)\n",
    "print(df_label.shape)\n",
    "print(df_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4368, 2)\n",
      "(4116, 2)\n",
      "(100753, 2)\n",
      "                 id            attribute_ids\n",
      "0  1027bc2aeca8e1a8              13 903 1092\n",
      "1  102cb701e5718d70             147 639 1035\n",
      "2  1048e4b13229f27d                  438 369\n",
      "3  105b6c58db321045                 121 1035\n",
      "4  105f044288493432  348 418 542 579 624 796\n"
     ]
    }
   ],
   "source": [
    "# train test valid split \n",
    "msk = np.random.rand(len(df_train)) < 0.96\n",
    "train = df_train[msk]\n",
    "valid  = df_train[~msk]\n",
    "msk = np.random.rand(len(train)) < 0.96\n",
    "test = train[~msk]\n",
    "train = train[msk]\n",
    "train.to_csv(\"train.csv\",index=None)\n",
    "test.to_csv(\"test.csv\",index=None)\n",
    "valid.to_csv(\"valid.csv\",index=None)\n",
    "print(pd.read_csv('valid.csv').shape)\n",
    "print(pd.read_csv('test.csv').shape)\n",
    "print(pd.read_csv('train.csv').shape)\n",
    "print(pd.read_csv('valid.csv').head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_onehot(tags):\n",
    "    '''converts a string of space seperated\n",
    "    tags to one hot repersentation'''\n",
    "    tags_list = tags.split()\n",
    "    ten = torch.zeros((df_label.shape[0]))\n",
    "    for i in tags_list:\n",
    "        ten[int(i)] = 1\n",
    "    return ten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class givendataset(Dataset):\n",
    "    \"\"\" dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a PIL image.\n",
    "        \"\"\"\n",
    "        self.frame = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.root_dir,self.frame['id'][idx])\n",
    "        image = Image.open(img_name+'.png')\n",
    "       \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        image = torchvision.transforms.ToTensor()(image)\n",
    "        image = transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])(image)\n",
    "        tags = to_onehot(self.frame['attribute_ids'][idx])\n",
    "        sample = {'image': image, 'tags': tags}\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_trans = torchvision.transforms.Compose([\n",
    "                        torchvision.transforms.Resize((SIZE,SIZE), interpolation=2),\n",
    "                        torchvision.transforms.RandomHorizontalFlip(p=0.5)])\n",
    "test_trans = torchvision.transforms.Compose([\n",
    "                        torchvision.transforms.Resize((SIZE,SIZE), interpolation=2)])\n",
    "train_dataset = givendataset('train.csv',root + 'train',train_trans )\n",
    "test_dataset = givendataset('test.csv',root + 'train',test_trans )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 400, 400])\n",
      "torch.Size([1103])\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset[10]['image'].shape)\n",
    "print(train_dataset[10]['tags'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset,batch_size=BATCH_SIZE,shuffle=True,num_workers=2)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset,batch_size=BATCH_SIZE,shuffle=True,num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=2048, out_features=2048, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Dropout(p=0.5)\n",
      "  (3): Linear(in_features=2048, out_features=1103, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet101(pretrained=False)\n",
    "model.load_state_dict(torch.load('../input/resnet101/resnet101.pth')) #loading imagenet weights\n",
    "model.fc = torch.nn.Sequential(\n",
    "        torch.nn.Linear(in_features=2048, out_features=2048, bias=True),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Dropout(p=0.5),\n",
    "        torch.nn.Linear(in_features=2048, out_features=df_label.shape[0], bias=True))\n",
    "print(model.fc)\n",
    "for i in model.parameters():\n",
    "    i.requires_grad=False\n",
    "for i in model.fc.parameters():\n",
    "    i.requires_grad=True\n",
    "for i in model.layer4.parameters():\n",
    "    i.requires_grad=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getpred(path,root,threshold=0.2):\n",
    "    '''path to CSV file, root folder for images \n",
    "    and threshold '''\n",
    "    df_test = pd.read_csv(path)\n",
    "    batch = 100\n",
    "    test_dataset = givendataset(path,root,test_trans)\n",
    "    test_loader  = torch.utils.data.DataLoader(test_dataset,batch_size=batch,shuffle=False)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "         for j,i in enumerate(test_loader):\n",
    "            data = i['image'].type(torch.FloatTensor)\n",
    "            target = i['tags'].type(torch.FloatTensor)\n",
    "            if train_on_gpu: # move tensors to GPU if CUDA is available\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            out = (torch.nn.Sigmoid()(model(data).cpu().detach())).numpy()\n",
    "            for l in range(out.shape[0]):\n",
    "                df_test['attribute_ids'][j*batch + l] = \" \".join([str(i) for i in np.argwhere(out[l] > threshold)[:,0].tolist()])\n",
    "    model.train()\n",
    "    return df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getF2(df1,df2,epsilon=0.0000001):\n",
    "    ''' F2 scores of two dataframes with attribute_ids\n",
    "    column containing class labels\n",
    "    df1 is true dataframe\n",
    "    df2 is predicted dataframe '''\n",
    "    assert df1.shape == df2.shape\n",
    "    beta = 2\n",
    "    i = 0.0\n",
    "    for index in range(df1.shape[0]):\n",
    "        y1 = to_onehot(df1['attribute_ids'][index])\n",
    "        y2 = to_onehot(df2['attribute_ids'][index])\n",
    "        true_positives = (y1 * y2).sum()\n",
    "        predicted_positives = y2.sum()\n",
    "        possible_positives = y1.sum()\n",
    "        precision = true_positives / (predicted_positives + epsilon)\n",
    "        recall = true_positives / (possible_positives + epsilon)\n",
    "        i += (((1+beta**2)*precision*recall) / ((beta**2)*precision+recall+epsilon))\n",
    "    return i/(df1.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_on_gpu = torch.cuda.is_available()\n",
    "if train_on_gpu:\n",
    "    model.cuda()\n",
    "pos_wei=torch.tensor(4*np.ones((df_label.shape[0]))).type(torch.FloatTensor)\n",
    "criterion = torch.nn.BCEWithLogitsLoss(reduction='mean',pos_weight=pos_wei).cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.003)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=4, gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after    128 images loss is 0.70170\n",
      "after  10112 images loss is 0.04458\n",
      "after  20096 images loss is 0.03635\n",
      "after  30080 images loss is 0.03259\n",
      "after  40064 images loss is 0.03393\n",
      "after  50048 images loss is 0.03032\n",
      "after  60032 images loss is 0.03156\n",
      "after  70016 images loss is 0.02976\n",
      "after  80000 images loss is 0.02729\n",
      "after  89984 images loss is 0.03001\n",
      "after  99968 images loss is 0.02726\n",
      "F2 score is 0.43066\n",
      "Epoch: 1 \tTraining Loss: 0.035227 \tValidation Loss: 0.028107\n",
      "Validation loss decreased (inf --> 0.028107).  Saving model ...\n",
      "F2 score increased (0.000000 --> 0.430664).  Saving model ...\n",
      "after    128 images loss is 0.02569\n",
      "after  10112 images loss is 0.02805\n",
      "after  20096 images loss is 0.03102\n",
      "after  30080 images loss is 0.02694\n",
      "after  40064 images loss is 0.02717\n",
      "after  50048 images loss is 0.02640\n",
      "after  60032 images loss is 0.02990\n",
      "after  70016 images loss is 0.02790\n",
      "after  80000 images loss is 0.02830\n",
      "after  89984 images loss is 0.02677\n",
      "after  99968 images loss is 0.02685\n",
      "F2 score is 0.46071\n",
      "Epoch: 2 \tTraining Loss: 0.027489 \tValidation Loss: 0.025852\n",
      "Validation loss decreased (0.028107 --> 0.025852).  Saving model ...\n",
      "F2 score increased (0.430664 --> 0.460709).  Saving model ...\n",
      "after    128 images loss is 0.02597\n",
      "after  10112 images loss is 0.02683\n",
      "after  20096 images loss is 0.02447\n",
      "after  30080 images loss is 0.02550\n",
      "after  40064 images loss is 0.02375\n",
      "after  50048 images loss is 0.02736\n",
      "after  60032 images loss is 0.02313\n",
      "after  70016 images loss is 0.02336\n",
      "after  80000 images loss is 0.02604\n",
      "after  89984 images loss is 0.02500\n",
      "after  99968 images loss is 0.02582\n",
      "F2 score is 0.50026\n",
      "Epoch: 3 \tTraining Loss: 0.025216 \tValidation Loss: 0.024252\n",
      "Validation loss decreased (0.025852 --> 0.024252).  Saving model ...\n",
      "F2 score increased (0.460709 --> 0.500258).  Saving model ...\n",
      "after    128 images loss is 0.02261\n",
      "after  10112 images loss is 0.02336\n",
      "after  20096 images loss is 0.02209\n",
      "after  30080 images loss is 0.02227\n",
      "after  40064 images loss is 0.02611\n",
      "after  50048 images loss is 0.02497\n",
      "after  60032 images loss is 0.02317\n",
      "after  70016 images loss is 0.02377\n",
      "after  80000 images loss is 0.02345\n",
      "after  89984 images loss is 0.02268\n",
      "after  99968 images loss is 0.02463\n",
      "F2 score is 0.51855\n",
      "Epoch: 4 \tTraining Loss: 0.023588 \tValidation Loss: 0.023289\n",
      "Validation loss decreased (0.024252 --> 0.023289).  Saving model ...\n",
      "F2 score increased (0.500258 --> 0.518551).  Saving model ...\n",
      "after    128 images loss is 0.02133\n",
      "after  10112 images loss is 0.02262\n",
      "after  20096 images loss is 0.02231\n",
      "after  30080 images loss is 0.02222\n",
      "after  40064 images loss is 0.02211\n",
      "after  50048 images loss is 0.02091\n",
      "after  60032 images loss is 0.02312\n",
      "after  70016 images loss is 0.02194\n",
      "after  80000 images loss is 0.02374\n",
      "after  89984 images loss is 0.02582\n",
      "after  99968 images loss is 0.02474\n",
      "F2 score is 0.52616\n",
      "Epoch: 5 \tTraining Loss: 0.022341 \tValidation Loss: 0.022725\n",
      "Validation loss decreased (0.023289 --> 0.022725).  Saving model ...\n",
      "F2 score increased (0.518551 --> 0.526163).  Saving model ...\n",
      "after    128 images loss is 0.02276\n",
      "after  10112 images loss is 0.02151\n",
      "after  20096 images loss is 0.02144\n",
      "after  30080 images loss is 0.01980\n",
      "after  40064 images loss is 0.02092\n",
      "after  50048 images loss is 0.02130\n",
      "after  60032 images loss is 0.02110\n",
      "after  70016 images loss is 0.01955\n",
      "after  80000 images loss is 0.01928\n",
      "after  89984 images loss is 0.01770\n",
      "after  99968 images loss is 0.01877\n",
      "F2 score is 0.55178\n",
      "Epoch: 6 \tTraining Loss: 0.020328 \tValidation Loss: 0.022098\n",
      "Validation loss decreased (0.022725 --> 0.022098).  Saving model ...\n",
      "F2 score increased (0.526163 --> 0.551782).  Saving model ...\n",
      "after    128 images loss is 0.01741\n",
      "after  10112 images loss is 0.02057\n",
      "after  20096 images loss is 0.01688\n",
      "after  30080 images loss is 0.02021\n",
      "after  40064 images loss is 0.01864\n",
      "after  50048 images loss is 0.01951\n",
      "after  60032 images loss is 0.01967\n",
      "after  70016 images loss is 0.01790\n",
      "after  80000 images loss is 0.01597\n",
      "after  89984 images loss is 0.01860\n",
      "after  99968 images loss is 0.01886\n",
      "F2 score is 0.55481\n",
      "Epoch: 7 \tTraining Loss: 0.019366 \tValidation Loss: 0.022081\n",
      "Validation loss decreased (0.022098 --> 0.022081).  Saving model ...\n",
      "F2 score increased (0.551782 --> 0.554814).  Saving model ...\n",
      "after    128 images loss is 0.01793\n",
      "after  10112 images loss is 0.02126\n",
      "after  20096 images loss is 0.01769\n",
      "after  30080 images loss is 0.02001\n",
      "after  40064 images loss is 0.02036\n",
      "after  50048 images loss is 0.01743\n",
      "after  60032 images loss is 0.01872\n",
      "after  70016 images loss is 0.01981\n",
      "after  80000 images loss is 0.01706\n",
      "after  89984 images loss is 0.02038\n",
      "after  99968 images loss is 0.01799\n",
      "F2 score is 0.55543\n",
      "Epoch: 8 \tTraining Loss: 0.018548 \tValidation Loss: 0.021708\n",
      "Validation loss decreased (0.022081 --> 0.021708).  Saving model ...\n",
      "F2 score increased (0.554814 --> 0.555434).  Saving model ...\n",
      "after    128 images loss is 0.02045\n",
      "after  10112 images loss is 0.01683\n",
      "after  20096 images loss is 0.01624\n",
      "after  30080 images loss is 0.01908\n",
      "after  40064 images loss is 0.01790\n",
      "after  50048 images loss is 0.01802\n",
      "after  60032 images loss is 0.01779\n",
      "after  70016 images loss is 0.01840\n",
      "after  80000 images loss is 0.01832\n",
      "after  89984 images loss is 0.01793\n",
      "after  99968 images loss is 0.01809\n",
      "F2 score is 0.55920\n",
      "Epoch: 9 \tTraining Loss: 0.017738 \tValidation Loss: 0.021810\n",
      "F2 score increased (0.555434 --> 0.559204).  Saving model ...\n",
      "after    128 images loss is 0.01542\n",
      "after  10112 images loss is 0.01488\n",
      "after  20096 images loss is 0.01861\n",
      "after  30080 images loss is 0.01688\n",
      "after  40064 images loss is 0.01508\n",
      "after  50048 images loss is 0.01689\n",
      "after  60032 images loss is 0.01559\n",
      "after  70016 images loss is 0.01753\n",
      "after  80000 images loss is 0.01527\n",
      "after  89984 images loss is 0.01585\n",
      "after  99968 images loss is 0.01740\n",
      "F2 score is 0.56652\n",
      "Epoch: 10 \tTraining Loss: 0.016249 \tValidation Loss: 0.022220\n",
      "F2 score increased (0.559204 --> 0.566520).  Saving model ...\n",
      "after    128 images loss is 0.01428\n",
      "after  10112 images loss is 0.01536\n",
      "after  20096 images loss is 0.01381\n",
      "after  30080 images loss is 0.01530\n",
      "after  40064 images loss is 0.01352\n",
      "after  50048 images loss is 0.01518\n",
      "after  60032 images loss is 0.01528\n",
      "after  70016 images loss is 0.01366\n",
      "after  80000 images loss is 0.01699\n",
      "after  89984 images loss is 0.01791\n",
      "after  99968 images loss is 0.01553\n",
      "F2 score is 0.56408\n",
      "Epoch: 11 \tTraining Loss: 0.015538 \tValidation Loss: 0.022111\n",
      "after    128 images loss is 0.01512\n",
      "after  10112 images loss is 0.01396\n",
      "after  20096 images loss is 0.01553\n",
      "after  30080 images loss is 0.01586\n",
      "after  40064 images loss is 0.01658\n",
      "after  50048 images loss is 0.01540\n",
      "after  60032 images loss is 0.01305\n",
      "after  70016 images loss is 0.01421\n",
      "after  80000 images loss is 0.01437\n",
      "after  89984 images loss is 0.01471\n",
      "after  99968 images loss is 0.01529\n",
      "F2 score is 0.56609\n",
      "Epoch: 12 \tTraining Loss: 0.014894 \tValidation Loss: 0.022379\n",
      "after    128 images loss is 0.01478\n",
      "after  10112 images loss is 0.01414\n",
      "after  20096 images loss is 0.01397\n",
      "after  30080 images loss is 0.01447\n",
      "after  40064 images loss is 0.01447\n",
      "after  50048 images loss is 0.01400\n",
      "after  60032 images loss is 0.01447\n",
      "after  70016 images loss is 0.01352\n",
      "after  80000 images loss is 0.01564\n",
      "after  89984 images loss is 0.01574\n",
      "after  99968 images loss is 0.01561\n",
      "F2 score is 0.56829\n",
      "Epoch: 13 \tTraining Loss: 0.014330 \tValidation Loss: 0.022985\n",
      "F2 score increased (0.566520 --> 0.568291).  Saving model ...\n",
      "after    128 images loss is 0.01273\n",
      "after  10112 images loss is 0.01352\n",
      "after  20096 images loss is 0.01320\n",
      "after  30080 images loss is 0.01397\n",
      "after  40064 images loss is 0.01246\n",
      "after  50048 images loss is 0.01321\n",
      "after  60032 images loss is 0.01038\n",
      "after  70016 images loss is 0.01293\n",
      "after  80000 images loss is 0.01187\n",
      "after  89984 images loss is 0.01270\n",
      "after  99968 images loss is 0.01312\n",
      "F2 score is 0.56734\n",
      "Epoch: 14 \tTraining Loss: 0.013313 \tValidation Loss: 0.023448\n",
      "after    128 images loss is 0.01267\n",
      "after  10112 images loss is 0.01344\n",
      "after  20096 images loss is 0.01124\n",
      "after  30080 images loss is 0.01375\n",
      "after  40064 images loss is 0.01201\n",
      "after  50048 images loss is 0.01181\n",
      "after  60032 images loss is 0.01444\n",
      "after  70016 images loss is 0.01398\n",
      "after  80000 images loss is 0.01288\n",
      "after  89984 images loss is 0.01279\n",
      "after  99968 images loss is 0.01161\n",
      "F2 score is 0.56839\n",
      "Epoch: 15 \tTraining Loss: 0.012876 \tValidation Loss: 0.023628\n",
      "F2 score increased (0.568291 --> 0.568386).  Saving model ...\n",
      "after    128 images loss is 0.01267\n",
      "after  10112 images loss is 0.01150\n",
      "after  20096 images loss is 0.01105\n",
      "after  30080 images loss is 0.01158\n",
      "after  40064 images loss is 0.01144\n",
      "after  50048 images loss is 0.01251\n",
      "after  60032 images loss is 0.01378\n",
      "after  70016 images loss is 0.01377\n",
      "after  80000 images loss is 0.01237\n",
      "after  89984 images loss is 0.01154\n",
      "after  99968 images loss is 0.01218\n",
      "F2 score is 0.56197\n",
      "Epoch: 16 \tTraining Loss: 0.012513 \tValidation Loss: 0.024989\n",
      "after    128 images loss is 0.01174\n",
      "after  10112 images loss is 0.01131\n",
      "after  20096 images loss is 0.01343\n",
      "after  30080 images loss is 0.01252\n",
      "after  40064 images loss is 0.01203\n",
      "after  50048 images loss is 0.01198\n",
      "after  60032 images loss is 0.01192\n",
      "after  70016 images loss is 0.01318\n",
      "after  80000 images loss is 0.01288\n",
      "after  89984 images loss is 0.01053\n",
      "after  99968 images loss is 0.01310\n",
      "F2 score is 0.56920\n",
      "Epoch: 17 \tTraining Loss: 0.012237 \tValidation Loss: 0.024672\n",
      "F2 score increased (0.568386 --> 0.569201).  Saving model ...\n",
      "after    128 images loss is 0.01161\n",
      "after  10112 images loss is 0.01111\n",
      "after  20096 images loss is 0.01122\n",
      "after  30080 images loss is 0.01219\n",
      "after  40064 images loss is 0.01120\n",
      "after  50048 images loss is 0.01155\n",
      "after  60032 images loss is 0.01142\n",
      "after  70016 images loss is 0.01180\n",
      "after  80000 images loss is 0.01171\n",
      "after  89984 images loss is 0.01392\n",
      "after  99968 images loss is 0.01017\n",
      "F2 score is 0.56615\n",
      "Epoch: 18 \tTraining Loss: 0.011651 \tValidation Loss: 0.025289\n",
      "after    128 images loss is 0.01192\n",
      "after  10112 images loss is 0.01146\n",
      "after  20096 images loss is 0.01075\n",
      "after  30080 images loss is 0.01132\n",
      "after  40064 images loss is 0.01178\n",
      "after  50048 images loss is 0.01171\n",
      "after  60032 images loss is 0.01198\n",
      "after  70016 images loss is 0.01069\n",
      "after  80000 images loss is 0.01157\n",
      "after  89984 images loss is 0.01082\n",
      "after  99968 images loss is 0.00948\n",
      "F2 score is 0.56517\n",
      "Epoch: 19 \tTraining Loss: 0.011401 \tValidation Loss: 0.025452\n",
      "after    128 images loss is 0.01122\n",
      "after  10112 images loss is 0.01100\n",
      "after  20096 images loss is 0.01197\n",
      "after  30080 images loss is 0.01139\n",
      "after  40064 images loss is 0.01234\n",
      "after  50048 images loss is 0.01120\n",
      "after  60032 images loss is 0.01101\n",
      "after  70016 images loss is 0.01121\n",
      "after  80000 images loss is 0.01189\n",
      "after  89984 images loss is 0.01132\n",
      "after  99968 images loss is 0.01007\n",
      "F2 score is 0.56188\n",
      "Epoch: 20 \tTraining Loss: 0.011194 \tValidation Loss: 0.026193\n"
     ]
    }
   ],
   "source": [
    "n_epochs = EPOCH # number of epochs to train the model\n",
    "test_loss_min = np.inf # track change in validation loss  \n",
    "F2_max    = 0.0\n",
    "for epoch in range(1, n_epochs+1):\n",
    "    train_loss = 0.0 # keep track of training and validation loss\n",
    "    test_loss = 0.0\n",
    "    ###################\n",
    "    # train the model #\n",
    "    ###################\n",
    "    model.train()\n",
    "    for p, i in enumerate(train_loader,1):\n",
    "        data = i['image'].type(torch.FloatTensor)\n",
    "        target = i['tags'].type(torch.FloatTensor)\n",
    "        if train_on_gpu: # move tensors to GPU if CUDA is available\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        optimizer.zero_grad() # clear the gradients of all optimized variables\n",
    "        output = model(data) # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        loss = criterion(output, target) # calculate the batch loss\n",
    "        loss.backward() #compute gradient of the loss with respect to model parameters\n",
    "        optimizer.step() # perform a single optimization step (parameter update)\n",
    "        train_loss += loss.item()*data.size(0) # update training loss\n",
    "        \n",
    "        if p % PRINT_EVERY == 1: #print loss every few batches\n",
    "            print(\"after {:6} images loss is {:.5f}\".format(p*BATCH_SIZE,loss.item()))\n",
    "    \n",
    "    del data,target #free some GPU mem \n",
    "    ######################    \n",
    "    # validate the model #\n",
    "    ######################\n",
    "    model.eval()\n",
    "    for i in test_loader:\n",
    "        data = i['image'].type(torch.FloatTensor)\n",
    "        target = i['tags'].type(torch.FloatTensor)\n",
    "        if train_on_gpu: # move tensors to GPU if CUDA is available\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        output = model(data)# forward pass: compute predicted outputs by passing inputs to the model\n",
    "        loss = criterion(output, target)# calculate the batch loss\n",
    "        test_loss += loss.item()*data.size(0) # update average validation loss \n",
    "    \n",
    "    #get some idea of F2 score threshold is set to 0.2\n",
    "    df_test_pred = getpred('test.csv',root + 'train/',0.2)\n",
    "    df_test = pd.read_csv('test.csv')\n",
    "    F2 = getF2(df_test,df_test_pred)\n",
    "    print(\"F2 score is {:.5f}\".format(F2))\n",
    "    \n",
    "    # calculate average losses\n",
    "    train_loss = train_loss/len(train_loader.dataset)\n",
    "    test_loss = test_loss/len(test_loader.dataset)\n",
    "    scheduler.step()\n",
    "        \n",
    "    # print training/validation statistics \n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
    "        epoch, train_loss, test_loss))\n",
    "    \n",
    "    # save model if validation loss has decreased\n",
    "    if test_loss <= test_loss_min:\n",
    "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "        test_loss_min,\n",
    "        test_loss))\n",
    "        torch.save(model.state_dict(), 'model_cifar.pt')\n",
    "        test_loss_min = test_loss\n",
    "    if F2 >= F2_max:\n",
    "        print('F2 score increased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "        F2_max,F2))\n",
    "        torch.save(model.state_dict(), 'model_cifar_.pt')\n",
    "        F2_max = F2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findThre(start, end, step):\n",
    "    '''finds the Threshold from the range'''\n",
    "    a = np.arange(start, end, step)\n",
    "    df_valid = pd.read_csv('test.csv')\n",
    "    b = []\n",
    "    for i in range(a.shape[0]):\n",
    "        df_test = getpred('test.csv',root + 'train/',a[i])\n",
    "        f2 = getF2(df_valid,df_test).item()\n",
    "        print(\"for threshold {:.3f}     score is {:.6f}\".format(a[i],f2))\n",
    "        b.append(f2)\n",
    "    return a[b.index(max(b))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for threshold 0.100     score is 0.546024\n",
      "for threshold 0.200     score is 0.569201\n",
      "for threshold 0.300     score is 0.560389\n",
      "for threshold 0.400     score is 0.543734\n",
      "for threshold 0.500     score is 0.521868\n",
      "for threshold 0.600     score is 0.492648\n",
      "Rough estimate is 0.200000\n",
      "for threshold 0.150     score is 0.562719\n",
      "for threshold 0.183     score is 0.567865\n",
      "for threshold 0.216     score is 0.568553\n",
      "for threshold 0.249     score is 0.566841\n",
      "Final estimate is 0.216000\n",
      "                 id                                      attribute_ids\n",
      "0  1027bc2aeca8e1a8                                13 671 698 813 1092\n",
      "1  102cb701e5718d70                                       147 189 1034\n",
      "2  1048e4b13229f27d                                            369 438\n",
      "3  105b6c58db321045                                       121 369 1035\n",
      "4  105f044288493432  147 189 259 418 541 542 543 579 581 753 813 94...\n",
      "                 id            attribute_ids\n",
      "0  1027bc2aeca8e1a8              13 903 1092\n",
      "1  102cb701e5718d70             147 639 1035\n",
      "2  1048e4b13229f27d                  438 369\n",
      "3  105b6c58db321045                 121 1035\n",
      "4  105f044288493432  348 418 542 579 624 796\n",
      "Final F2 score is 0.56642\n",
      "CPU times: user 9min 14s, sys: 6min 40s, total: 15min 55s\n",
      "Wall time: 16min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model.load_state_dict(torch.load('model_cifar_.pt'))\n",
    "th = findThre(0.1,0.61,0.1) #find rough estimate\n",
    "print(\"Rough estimate is {:.6f}\".format(th))\n",
    "th = findThre(th - 0.05,th + 0.055,0.033) # final estimate\n",
    "print(\"Final estimate is {:.6f}\".format(th))\n",
    "df_test_pred = getpred('valid.csv',root + 'train/',th)\n",
    "df_test = pd.read_csv('valid.csv')\n",
    "print(df_test_pred.head())\n",
    "print(df_test.head())\n",
    "F2 = getF2(df_test,df_test_pred)\n",
    "print(\"Final F2 score is {:.5f}\".format(F2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 id                                      attribute_ids\n",
      "0  10023b2cc4ed5f68                           223 289 369 587 766 1059\n",
      "1  100fbe75ed8fd887                                        93 231 1039\n",
      "2  101b627524a04f19                                         79 420 784\n",
      "3  10234480c41284c6  147 480 483 501 522 725 737 738 776 830 1046 1068\n",
      "4  1023b0e2636dcea8  147 283 322 492 538 584 616 698 813 954 1046 1...\n"
     ]
    }
   ],
   "source": [
    "#generate the submission\n",
    "df_test = getpred(root + 'sample_submission.csv',root + 'test/',th)\n",
    "df_test.to_csv('submission.csv', index=False) \n",
    "print(df_test.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
