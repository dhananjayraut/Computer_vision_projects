{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ECNBRaRIePtP"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets,models,transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qvcae0X0eqZq"
   },
   "outputs": [],
   "source": [
    "#downloading and extracting dataset \n",
    "#note that the dataset was provided by udacity it may no longer be awailable\n",
    "!wget https://s3.amazonaws.com/content.udacity-data.com/courses/nd188/flower_data.zip\n",
    "!unzip flower_data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m_wsberEfArB"
   },
   "outputs": [],
   "source": [
    "data_dir = 'flower_data'\n",
    "train_dir = data_dir + '/train'\n",
    "valid_dir = data_dir + '/valid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "xxFVMRLIfB74",
    "outputId": "48b6dba9-2299-4929-bc01-f0750e320467"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "train_on_gpu = torch.cuda.is_available()\n",
    "print(train_on_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lfiANMztfGZa"
   },
   "outputs": [],
   "source": [
    "#defining trainsforms as our model takes 224 * 224 images\n",
    "#normalized with given numbers.\n",
    "\n",
    "train_transform = transforms.Compose([transforms.RandomResizedCrop(224),\n",
    "                                      transforms.RandomHorizontalFlip(0.5),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])])\n",
    "valid_transform = transforms.Compose([transforms.Resize((224,224)),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "vUInfkAffKAI",
    "outputId": "cf3d4a58-d7f6-4faa-a8d7-9889a267a8ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num training images:  6552\n",
      "Num test images:  818\n"
     ]
    }
   ],
   "source": [
    "train_data = datasets.ImageFolder(train_dir, transform=train_transform)\n",
    "valid_data = datasets.ImageFolder(valid_dir, transform=valid_transform)\n",
    "\n",
    "# print out some data stats\n",
    "print('Num training images: ', len(train_data))\n",
    "print('Num test images: ', len(valid_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TavsWM53fPLG"
   },
   "outputs": [],
   "source": [
    "#batch size is set to 128 you can reduce it if batch doesn't fit in your GPU memory.\n",
    "batch_size = 128\n",
    "\n",
    "# prepare data loaders\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, num_workers=0, shuffle=True,drop_last = True)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_data, batch_size=10, num_workers=0, shuffle=True,drop_last = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "Gcfv-b3NfX3u",
    "outputId": "8deeea88-9f4e-4be9-dd58-714f169dac1d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet152-b121ed2d.pth\" to /root/.torch/models/resnet152-b121ed2d.pth\n",
      "241530880it [00:05, 45435850.18it/s]\n"
     ]
    }
   ],
   "source": [
    "#we are using pretrained models provided by torchvision \n",
    "\n",
    "#you can replace this with other pretrained model but you have to make changes in FC layer accordingly.\n",
    "model = models.resnet152(pretrained=True)\n",
    "\n",
    "#redefining fully connected layer of the model to suit our need\n",
    "model.fc = torch.nn.Sequential(\n",
    "            torch.nn.Linear(2048, 1024, bias = True),\n",
    "            torch.nn.BatchNorm1d(1024),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.Dropout(0.5),\n",
    "            torch.nn.Linear(1024, 512, bias = True),\n",
    "            torch.nn.BatchNorm1d(512),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.Dropout(0.5),\n",
    "            torch.nn.Linear(512, 102)\n",
    "            )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4JFBoJg0gIm2"
   },
   "outputs": [],
   "source": [
    "#freezing some parameters \n",
    "#note that I unfreezed the layer before fully connected layer \n",
    "#it helps to improve performance.\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in model.layer4.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in model.fc.parameters():\n",
    "    param.requires_grad = True\n",
    "if train_on_gpu:\n",
    "    model.cuda()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2gCcyWh-gfUB"
   },
   "outputs": [],
   "source": [
    "#we are using standard crossentropyloss as our loss function and Adam optimizer.\n",
    "#and we are using learning rate scheduler provided by pytorch to change(reduce) learning\n",
    "#rate while training it will multiply Lr by 0.25 every 5 epoch.\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 610
    },
    "colab_type": "code",
    "id": "BCKArhZrhhex",
    "outputId": "56082532-a657-4399-b12e-be0b41272fd8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 3.151481 \tValidation Loss: 1.921961\n",
      "Validation loss decreased (inf --> 1.921961).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 1.524325 \tValidation Loss: 0.937873\n",
      "Validation loss decreased (1.921961 --> 0.937873).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 0.765732 \tValidation Loss: 0.494559\n",
      "Validation loss decreased (0.937873 --> 0.494559).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 0.491587 \tValidation Loss: 0.370547\n",
      "Validation loss decreased (0.494559 --> 0.370547).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 0.393055 \tValidation Loss: 0.325006\n",
      "Validation loss decreased (0.370547 --> 0.325006).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 0.265866 \tValidation Loss: 0.150962\n",
      "Validation loss decreased (0.325006 --> 0.150962).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 0.192284 \tValidation Loss: 0.138872\n",
      "Validation loss decreased (0.150962 --> 0.138872).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 0.183959 \tValidation Loss: 0.153490\n",
      "Epoch: 9 \tTraining Loss: 0.172690 \tValidation Loss: 0.139449\n",
      "Epoch: 10 \tTraining Loss: 0.153234 \tValidation Loss: 0.142897\n",
      "Epoch: 11 \tTraining Loss: 0.135772 \tValidation Loss: 0.133194\n",
      "Validation loss decreased (0.138872 --> 0.133194).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.134930 \tValidation Loss: 0.125739\n",
      "Validation loss decreased (0.133194 --> 0.125739).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.120541 \tValidation Loss: 0.116585\n",
      "Validation loss decreased (0.125739 --> 0.116585).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.119545 \tValidation Loss: 0.118570\n",
      "Epoch: 15 \tTraining Loss: 0.123024 \tValidation Loss: 0.117624\n",
      "Epoch: 16 \tTraining Loss: 0.113275 \tValidation Loss: 0.117818\n",
      "Epoch: 17 \tTraining Loss: 0.112612 \tValidation Loss: 0.116543\n",
      "Validation loss decreased (0.116585 --> 0.116543).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.118102 \tValidation Loss: 0.115978\n",
      "Validation loss decreased (0.116543 --> 0.115978).  Saving model ...\n",
      "Epoch: 19 \tTraining Loss: 0.111939 \tValidation Loss: 0.108067\n",
      "Validation loss decreased (0.115978 --> 0.108067).  Saving model ...\n",
      "Epoch: 20 \tTraining Loss: 0.113759 \tValidation Loss: 0.110990\n"
     ]
    }
   ],
   "source": [
    "# number of epochs to train the model\n",
    "n_epochs = 20\n",
    "\n",
    "valid_loss_min = np.Inf # track change in validation loss\n",
    "\n",
    "for epoch in range(1, n_epochs+1):\n",
    "\n",
    "    # keep track of training and validation loss\n",
    "    train_loss = 0.0\n",
    "    valid_loss = 0.0\n",
    "    \n",
    "    scheduler.step()\n",
    "    \n",
    "    ###################\n",
    "    # train the model #\n",
    "    ###################\n",
    "    model.train()\n",
    "    for data, target in train_loader:\n",
    "        # move tensors to GPU if CUDA is available\n",
    "        if train_on_gpu:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        # clear the gradients of all optimized variables\n",
    "        optimizer.zero_grad()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        # calculate the batch loss\n",
    "        loss = criterion(output, target)\n",
    "        # backward pass: compute gradient of the loss with respect to model parameters\n",
    "        loss.backward()\n",
    "        # perform a single optimization step (parameter update)\n",
    "        optimizer.step()\n",
    "        # update training loss\n",
    "        train_loss += loss.item()*data.size(0)\n",
    "        \n",
    "    ######################    \n",
    "    # validate the model #\n",
    "    ######################\n",
    "    model.eval()\n",
    "    for data, target in valid_loader:\n",
    "        # move tensors to GPU if CUDA is available\n",
    "        if train_on_gpu:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        # calculate the batch loss\n",
    "        loss = criterion(output, target)\n",
    "        # update average validation loss \n",
    "        valid_loss += loss.item()*data.size(0)\n",
    "    \n",
    "    # calculate average losses\n",
    "    train_loss = train_loss/len(train_loader.dataset)\n",
    "    valid_loss = valid_loss/len(valid_loader.dataset)\n",
    "        \n",
    "    # print training/validation statistics \n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
    "        epoch, train_loss, valid_loss))\n",
    "    \n",
    "    # save model if validation loss has decreased\n",
    "    if valid_loss <= valid_loss_min:\n",
    "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "        valid_loss_min,\n",
    "        valid_loss))\n",
    "        torch.save(model.state_dict(), 'model_cifar.pt')\n",
    "        valid_loss_min = valid_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Bg9cdsamhzCi"
   },
   "outputs": [],
   "source": [
    "#load model with least validation loss\n",
    "model.load_state_dict(torch.load('model_cifar.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1924
    },
    "colab_type": "code",
    "id": "b1_vugCLtzQK",
    "outputId": "ef15ea0c-fff0-4e38-cdd1-830fe3772ac0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.115012\n",
      "\n",
      "Test Accuracy of 0: 100% ( 7/ 7)\n",
      "Test Accuracy of 1: 100% ( 4/ 4)\n",
      "Test Accuracy of 2: 100% ( 6/ 6)\n",
      "Test Accuracy of 3: 100% ( 5/ 5)\n",
      "Test Accuracy of 4: 100% ( 6/ 6)\n",
      "Test Accuracy of 5: 90% ( 9/10)\n",
      "Test Accuracy of 6: 100% ( 5/ 5)\n",
      "Test Accuracy of 7: 100% ( 5/ 5)\n",
      "Test Accuracy of 8: 100% ( 1/ 1)\n",
      "Test Accuracy of 9: 100% ( 7/ 7)\n",
      "Test Accuracy of 10: 100% ( 2/ 2)\n",
      "Test Accuracy of 11: 100% (16/16)\n",
      "Test Accuracy of 12: 100% (11/11)\n",
      "Test Accuracy of 13: 100% ( 4/ 4)\n",
      "Test Accuracy of 14: 100% ( 6/ 6)\n",
      "Test Accuracy of 15: 100% ( 7/ 7)\n",
      "Test Accuracy of 16: 100% ( 4/ 4)\n",
      "Test Accuracy of 17: 100% ( 8/ 8)\n",
      "Test Accuracy of 18: 100% (12/12)\n",
      "Test Accuracy of 19: 100% ( 5/ 5)\n",
      "Test Accuracy of 20: 100% ( 2/ 2)\n",
      "Test Accuracy of 21: 100% ( 3/ 3)\n",
      "Test Accuracy of 22: 100% ( 1/ 1)\n",
      "Test Accuracy of 23: 100% ( 5/ 5)\n",
      "Test Accuracy of 24: 100% ( 7/ 7)\n",
      "Test Accuracy of 25: 100% ( 2/ 2)\n",
      "Test Accuracy of 26: 80% ( 8/10)\n",
      "Test Accuracy of 27: 100% ( 2/ 2)\n",
      "Test Accuracy of 28: 100% ( 3/ 3)\n",
      "Test Accuracy of 29: 100% ( 7/ 7)\n",
      "Test Accuracy of 30: 100% ( 7/ 7)\n",
      "Test Accuracy of 31: 100% ( 4/ 4)\n",
      "Test Accuracy of 32: 83% ( 5/ 6)\n",
      "Test Accuracy of 33: 100% ( 8/ 8)\n",
      "Test Accuracy of 34: 100% ( 4/ 4)\n",
      "Test Accuracy of 35: 100% ( 3/ 3)\n",
      "Test Accuracy of 36: 66% ( 4/ 6)\n",
      "Test Accuracy of 37: 100% ( 5/ 5)\n",
      "Test Accuracy of 38: 100% (16/16)\n",
      "Test Accuracy of 39: 100% ( 6/ 6)\n",
      "Test Accuracy of 40: 100% (14/14)\n",
      "Test Accuracy of 41: 100% ( 9/ 9)\n",
      "Test Accuracy of 42: 100% ( 4/ 4)\n",
      "Test Accuracy of 43: 100% (18/18)\n",
      "Test Accuracy of 44: 100% ( 3/ 3)\n",
      "Test Accuracy of 45: 100% ( 9/ 9)\n",
      "Test Accuracy of 46: 100% ( 8/ 8)\n",
      "Test Accuracy of 47: 100% ( 7/ 7)\n",
      "Test Accuracy of 48: 100% (11/11)\n",
      "Test Accuracy of 49: 96% (26/27)\n",
      "Test Accuracy of 50: 100% (10/10)\n",
      "Test Accuracy of 51: 88% ( 8/ 9)\n",
      "Test Accuracy of 52: 90% ( 9/10)\n",
      "Test Accuracy of 53: 100% ( 8/ 8)\n",
      "Test Accuracy of 54: 100% ( 9/ 9)\n",
      "Test Accuracy of 55: 100% ( 6/ 6)\n",
      "Test Accuracy of 56: 100% (13/13)\n",
      "Test Accuracy of 57: 100% ( 4/ 4)\n",
      "Test Accuracy of 58: 100% ( 1/ 1)\n",
      "Test Accuracy of 59: 100% (14/14)\n",
      "Test Accuracy of 60: 100% ( 6/ 6)\n",
      "Test Accuracy of 61: 66% ( 2/ 3)\n",
      "Test Accuracy of 62: 100% ( 8/ 8)\n",
      "Test Accuracy of 63: 100% ( 5/ 5)\n",
      "Test Accuracy of 64: 100% ( 7/ 7)\n",
      "Test Accuracy of 65: 100% ( 5/ 5)\n",
      "Test Accuracy of 66: 100% ( 2/ 2)\n",
      "Test Accuracy of 67: 100% ( 7/ 7)\n",
      "Test Accuracy of 68: 100% ( 5/ 5)\n",
      "Test Accuracy of 69: 100% ( 1/ 1)\n",
      "Test Accuracy of 70: 100% ( 7/ 7)\n",
      "Test Accuracy of 71: 100% ( 5/ 5)\n",
      "Test Accuracy of 72: 87% ( 7/ 8)\n",
      "Test Accuracy of 73: 100% (18/18)\n",
      "Test Accuracy of 74: 93% (14/15)\n",
      "Test Accuracy of 75: 100% (12/12)\n",
      "Test Accuracy of 76: 95% (19/20)\n",
      "Test Accuracy of 77: 100% (21/21)\n",
      "Test Accuracy of 78: 100% (11/11)\n",
      "Test Accuracy of 79: 100% ( 4/ 4)\n",
      "Test Accuracy of 80: 100% ( 5/ 5)\n",
      "Test Accuracy of 81: 100% (12/12)\n",
      "Test Accuracy of 82: 100% (18/18)\n",
      "Test Accuracy of 83: 100% (13/13)\n",
      "Test Accuracy of 84: 92% (12/13)\n",
      "Test Accuracy of 85: 90% ( 9/10)\n",
      "Test Accuracy of 86: 100% ( 5/ 5)\n",
      "Test Accuracy of 87: 100% ( 5/ 5)\n",
      "Test Accuracy of 88: 100% ( 6/ 6)\n",
      "Test Accuracy of 89: 92% (23/25)\n",
      "Test Accuracy of 90: 100% (16/16)\n",
      "Test Accuracy of 91: 100% ( 3/ 3)\n",
      "Test Accuracy of 92: 100% ( 2/ 2)\n",
      "Test Accuracy of 93: 88% ( 8/ 9)\n",
      "Test Accuracy of 94: 100% ( 2/ 2)\n",
      "Test Accuracy of 95: 83% ( 5/ 6)\n",
      "Test Accuracy of 96: 100% (14/14)\n",
      "Test Accuracy of 97: 100% (12/12)\n",
      "Test Accuracy of 98: 80% ( 8/10)\n",
      "Test Accuracy of 99: 100% ( 6/ 6)\n",
      "Test Accuracy of 100: 100% (10/10)\n",
      "Test Accuracy of 101: 83% ( 5/ 6)\n",
      "\n",
      "Test Accuracy (Overall): 97% (788/810)\n"
     ]
    }
   ],
   "source": [
    "# track test loss \n",
    "# over all flower classes\n",
    "test_loss = 0.0\n",
    "class_correct = list(0. for i in range(102))\n",
    "class_total = list(0. for i in range(102))\n",
    "\n",
    "model.eval() # eval mode\n",
    "\n",
    "# iterate over test data\n",
    "for data, target in valid_loader:\n",
    "                                                                        # move tensors to GPU if CUDA is available\n",
    "    if train_on_gpu:\n",
    "        data, target = data.cuda(), target.cuda()\n",
    "                                                                        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "    output = model(data)\n",
    "                                                                        # calculate the batch loss\n",
    "    loss = criterion(output, target)\n",
    "                                                                        # update  test loss \n",
    "    test_loss += loss.item()*data.size(0)\n",
    "                                                                        # convert output probabilities to predicted class\n",
    "    _ , pred = torch.max(output, 1)    \n",
    "                                                                        # compare predictions to true label\n",
    "    correct_tensor = pred.eq(target.data.view_as(pred))\n",
    "    correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n",
    "    for i in range(10):\n",
    "        label = target.data[i]\n",
    "        class_correct[label] += correct[i].item()\n",
    "        class_total[label] += 1\n",
    "      \n",
    "# calculate avg test loss\n",
    "test_loss = test_loss/len(valid_loader.dataset)\n",
    "print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
    "\n",
    "#printing \n",
    "for i in range(102):\n",
    "    if class_total[i] > 0:\n",
    "        print('Test Accuracy of %d: %2d%% (%2d/%2d)' % (\n",
    "             i ,100 * class_correct[i] / class_total[i],\n",
    "            np.sum(class_correct[i]), np.sum(class_total[i])))\n",
    "\n",
    "print('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n",
    "    100. * np.sum(class_correct) / np.sum(class_total),\n",
    "    np.sum(class_correct), np.sum(class_total)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "We created a image classifier with above 97% accuracy with just few lines of code thanks to pretrained model\n",
    "provided by torchvision. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "class.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
